# 2023-09-25 (月曜日)

* 余計な情報を言いすぎて本筋じゃないところを突っ込まれてしまいがち
  * 事前にしっかり説明しなきゃという気持ちが邪魔をしている
  * 細かいところが気になる人との話に向いていない気がする
  * ミスったらすぐ「余計なこと言ったんで、忘れてください」でいい気がする
* kubeがほっておいたら死んでた
  * とりあえず「Clean / Purge data」をやったら生き返ったっぽい
  * https://gotohayato.com/content/545/
* エリア口コミのバグが一番大変だった気がする
  * 調査の結果消さないことになったので工数が増加した
  * エリア単位でのアンロック情報がバックエンドから渡されてなかったので、意図する挙動にするには調整する必要があった


# 2023-09-26 (火曜日)

* 確認するときにいちいちコストがデカすぎる
  * 正直そこまで厳密に書く必要もない気がする
  * なのでそれに対応しようとして、準備をしまくるのはナンセンス
  * そういうものとして対応するのが賢そう
* バグの見積もりミスった
  * 一定のCTR率の差分などを確認しないと判断できない系のものはもう少し多めの方がいいかも
* pandasが便利すぎる
  * データ出しの時に色々試しやすくて良い
* dbクライアントとしてpythonライブラリを使っている
  * timeout時間を設定できて便利

# 2023-09-27 (水曜日)

* 重複チェック用のデータだしまあまあ大変だった
  * pandasあったので比較的楽だった
* チャットUIの本適用割と楽だったかも
* エリアOKの開発楽すぎる
  * 他の人がやれるようだったら知見共有的にも良かったかも

# 2023-09-28 (木曜日)

* エリアOKチラ見した感じだと、これはエリアOKじゃないの？って口コミがそれなりにある
  * 基準がぶっちゃけわかってない
  * 手順書のどこに書いてるのか見つけられてない

* 口コミなどをDBから非掲載にしたときにSolrの更新は不要？
  * 削除じゃないから問題ない？
  * →こっちはワンチャンいるかも
* 写真を非掲載にしているときだけ、すでに無効なものも処理しているのはなぜ？
  * もしかして他のもそうだけど、元々非掲載も取得できるだけ？
    * →QAはステータスによらずとってきている
  * →ただ口コミだと非掲載は事前に弾かれているっぽい
  * 無効と非掲載の概念が違う？？？
  * →踏まえて、UGC系はすでに無効なものもdenyするという仕様の理解で良いか確認する
    * ここでいう無効と非掲載は別の概念で良いかという質問もする
    * →別の概念で、未承認状態のときにenable=falseだからっぽい
  * →これは仕様にないので一旦このまま

*  workflowも検討しないとダメそう
   * そもそもworkflowとは？→ML Pipeline（「学習データの収集 → モデルの再学習 → 再学習済みのモデルによる予測」のような一連の処理の自動化）を実現できるツール
   * https://cyberagent.ai/blog/research/12898/ によると機能もりもりにすれば良いというわけではなさそう
   * むしろシンプルがいい説
   * またデータの傾向が大きく変わっていないかを監視する仕組みが必要かも
     * →一定の水準を超えていたらモデルを再学習するなどの判断軸になる
     * e.g. 1ヶ月間に投稿されるカテゴリの分布が去年の今頃と比べて変化している、など
 * 前処理済みのデータは別テーブル（or 別DB的なもの）で保持しておくのもいいかも
   * バッチ処理しやすそう
   * AIの結果と人間の結果を分離できそう
   * 後でデータ分析しやすいような設計にしておくとベストかも
     * 予測当時のプロンプトを載せる、確率値を載せるとか？
 * モデル自体のバージョン管理もしたい

 * ベロシティが上がっているので一見見積もりをミスったように見えるが、これは正しくなったという方が適切
   * 1日8時間という前提で見積もり直して、残業しているのだからベロシティは上がる


# 2023-09-29 (金曜日)

* 学習時は手元で実験できるようなデータ管理にして、推論時は本番環境のデータを後で処理をやり直したり、データ分析しやすいようなデータ管理にすると良さそう
* 今週はほとんどMTGがなく、作業時間がいっぱいあった
* エリアOKは手順書を見た感じルールベースで弾いてたりなど、ラベルとしてのブレがでかい可能性が高いので一旦全部一手でしっかりとした基準でチェックするがいいかも
  * 一定期間この運用をして、精度の高いデータが増えた時点で再度AI化を検討する
  * ちなみに直近10万件の口コミのうち、エリアOKを判定する対象の口コミは約26%
* 各データに対して、どこまで処理が完了しているか（掲載非掲載: done、金銀銅: done、センシティブ: not done、、、）を表しておくと非同期に処理できる？


# 2023-09-30 (土曜日)

* コード、データ、モデルのバージョンを管理するための方法を考える必要がある
  * データ側にどのモデルで予測した結果なのかの情報を持たせた方がいいかも？
    * データにモデルのバージョンを
    * モデルのバージョンとその時のコードはgitに持たせるとか？
    * つまりタグを切り出せる方がいいから別リポジトリの方が汎用性高い？
  * もっといい方法が知りたい気持ち
* SHに依頼を投げる前に、「〇〇がしたいんですけど、具体的にどんな情報が必要そうですか？」は聞いておいてもいいかも
  * 当たり前だけどあまりできていない気がする
  * 承認もらうというよりも利用しまくるくらいの気持ちのがいい
* 拒否口コミとか関係なく、人間に一定口コミを流すのはprobalityベースで判断してもいいかも？
  * ある閾値以下の口コミを人間に流して、ラベルをつけてもらう
  * ただこれだと現状のモデルの性能を後々測ることが難しくなる（自信がある口コミの予測性能が見れなくなるので）
* 本番リリース前に、一旦AIモデルによるprobつけだけして、全部人間の手で承認作業をしてもらうのはありかも
  * 性能が明確にわかる


# 2023-10-01 (日曜日)

* 今日は進捗が芳しくない

